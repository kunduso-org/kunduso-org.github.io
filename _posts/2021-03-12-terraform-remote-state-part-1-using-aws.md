---
title: "Terraform Remote State -Part 1: Using AWS"
date: 2021-03-12 11:34:39 +0000
categories: []
tags: []
---

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">When I started learning Terraform, I installed the tool, wrote Terraform configuration files, and ran the commands from my local (laptop). I did not put a lot of thought into understanding a remote state and how it is useful. As I continued learning, and as I started using Azure DevOps to automate infrastructure provisioning using Terraform, I realized the importance of using a remote state. In this post, <strong>I explore the idea of a remote-state in Terraform, why it is useful, and how to set that up.</strong> Then I will dive into exploring the remote-state with AWS.</span></span></span>

<em><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">PS: I explore the same idea in my next post (part 2) using Azure for the remote state. In part 3, I explore using a remote-state as a data source. These two posts are being worked on right now.</span></span></span></em>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">So that brings us to the question -<strong>What is a state? And, what is a remote state?</strong></span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Let me recap a bit so that we all are on the same page. The sequence of commands in terraform (usually) are <strong>init -&gt; validate -&gt; plan -&gt; apply</strong>. When <strong>"terraform apply"</strong> is run, terraform provisions resources as is requested in the configuration files and also stores information about the resource that it just provisioned in order to manage them. Say you changed a config value and re-ran the terraform steps (validate -&gt; plan -&gt; apply). <strong>How would the Terraform compiler know that it's a slight config change to an already provisioned resource and not a new resource request?</strong> That information (metadata) is stored in a state file, called <span style="text-decoration: underline"><strong>terraform.tfstate</strong></span>. By default, this file gets created in the same location from where the Terraform configuration files are executed. Now imagine the challenge when working in an automated, collaborative environment where we cannot take security lightly.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Automation:</strong> Say I am using Terraform config files in Azure pipelines hosted build machine to manage resources. Each time the terraform configuration files are run, the terraform.tfstate is created in the local workspace, and then once the build finishes, the workspace gets deleted, and the state file is lost. In the next run (since the previously created tfstate file is not available), terraform provisions resources once again. Depending upon the naming convention or logic, it can create unnecessary duplicate resources erroring out.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Collaboration:</strong> Say a team of developers is working on provisioning different infrastructure segments using the same repository to store the Terraform configuration files. In this case, if Developer 1 makes changes and runs the config (whether from local or from a build agent like Azure DevOps), the terraform.tfstate is no longer relevant or is getting lost after each automated run. Why? Because when Developer 2 runs the same Terraform commands, there will be a mismatch in resource configuration. And all this because none of these approaches refers to a shared location of the terraform.tfstate file.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Security:</strong> When Terraform creates the terraform.tfstate file after each apply run, it stores meta-data of the resources. This data is sensitive and needs to be stored securely with appropriate access control for only authorized users.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">HashiCorp has done a better job of explaining this concept in detail, and I'd recommend reading that here -<a href="https://www.terraform.io/docs/language/state/purpose.html" target="_blank" rel="noopener">Terraform state purpose</a>.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I hope that gave you a good understanding of what a state file is and how Terraform uses it. I now explore the idea of a remote-state. A remote-state is a state file that is stored remotely (and not the default <em>-locally</em>). Remotely could be a shared drive as well that is accessible from each developer's workspace. Terraform also supports Amazon S3, Azure Blog Storage, Terraform cloud, and much more remote-state storage. Although storing Terraform state file remotely is a step in the right direction, it opens up another challenge. What will happen to the remote state file when two parallel processes are trying to update the same terraform.tfstate as part of "terraform apply"? And that is where the concept of state locking is necessary to prevent concurrent access to the state file. Here is a better explanation of <strong><a href="https://www.terraform.io/docs/language/state/remote.html" target="_blank" rel="noopener">remote state</a></strong> and <strong><a href="https://www.terraform.io/docs/language/state/locking.html" target="_blank" rel="noopener">state locking</a></strong> from Terraform Docs.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I now delve into provisioning a <strong>remote state and lock for Terraform in AWS</strong>. There are two use cases I can think of as a developer explores the idea of using a remote state.</span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Use Case #1:</strong> Fresh terraform configuration. This use-case is when the terraform configurations have not been run, and no resources have been provisioned yet.</span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Use Case #2:</strong> Terraform configs have been used to provision resources and the terraform.tfstate file is currently stored locally.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">In the case of AWS, <em><strong>Terraform uses an Amazon S3 bucket and an Amazon Dynamo DB table to store the state file and the lock.</strong></em> That's a <span style="text-decoration: underline"><strong>pre-requisite</strong></span> to both the use cases. Below are the steps to add a remote state to a terraform configuration.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Step 1:</strong> Add the following block to the terraform configuration file. I have seen repositories (on GitHub) where there is a separate file by the name of <strong>"backend.tf"</strong> where the backend configuration is stored. I believe storing backend configuration in a separate file keeps the configuration accessible and readable, rather than adding that block to an existing Terraform configuration.</span></span></span>

https://gist.github.com/kunduso/6e1dba046e7889ec08f6b931175757ae

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">where the $(BackendBucketName) is the name of the Amazon S3 bucket that was created (pre-requisite),</span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">the $(PathToTFStateFile) is the path to the terraform.tfstate file stored inside the bucket, including the file name,</span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">the $(BucketRegion) is the location of the bucket, and</span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">the $(BackendLockTableName) is the name of the Amazon DynamoDB table to store the lock.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000"><strong>Step 2:</strong> After the backend block is added to our Terraform configuration, we have to inform Terraform to initiate the backend. That is done with the <strong>"terraform init"</strong> command. <em>Whether you have an existing terraform.tfstate in local (use-case 2) or running "terraform init" for the first time (use-case 1), we have to start with the "terraform init" command.</em></span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">The IAM user credentials that will be used by the Terraform compiler to run the Terraform configuration need to have access to the S3 bucket and the DynamoDB table to store the state file and lock.</span></span></span>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">A policy file can be created, such as shown below, and associated with the user. That ensures that the user will have sufficient permission to work with the backend resources -S3 bucket and DynamoDB table. I know it is easy to give administrator rights to the user, but more than the below is not required to manage the backend.</span></span></span>

https://gist.github.com/kunduso/bf94f1aa5e683ed66539458a9a44138d

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Here is a link to a repository where I have the backend configured -<strong><a href="https://github.com/kunduso/Terraform-AWS-RemoteBackend" target="_blank" rel="noopener">Terraform-AWS-RemoteBackend</a></strong>.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">This repository has a <strong>backend.tf</strong> file with the details of an Amazon S3 backend. The skeleton code is to configure a VPC, so I added that permission to the IAM user too, along with the policy state above. <span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I also stored the <strong>backend-role-policy.json</strong> file in the repo. </span></span></span></span></span></span><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">The <strong>azure-pipelines.yaml</strong> file has all the Terraform steps in detail.</span></span></span>

<em><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Please note that t</span></span></span><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">he Amazon DynamoDB table name, the Amazon S3 bucket name, and the path to the key should match in policy file and the backend configuration. That way, the policy file can be restrictive.</span></span></span></em>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Remote backend in Terraform is a crucial concept to understand as you move towards adopting an infrastructure-as-code mindset. I hope you found this post useful, and let me know if you have any questions or comments.</span></span></span>
