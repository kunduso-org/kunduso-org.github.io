---
title: "Download Amazon S3 bucket into an Amazon EC2 instance in 5 steps using user data and Terraform"
date: 2021-12-17 07:04:00 +0000
categories: []
tags: []
---

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I required a few files and folders on an Amazon EC2 instance as part of the provisioning process. So, the objective was to <strong>upload these files and folders into an Amazon S3 bucket and download them from the Amazon EC2 instance</strong> with the assistance of the user data script and Terraform.</span></span></span><!--more-->
<em><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Note: As a reader of this note, I assume that you know Amazon S3 and Amazon EC2 instance and their usage. If you want to know more, please refer to AWS-Docs on Amazon S3 and Amazon EC2.</span></span></span></em>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I broke down this use case into <strong>five minor use cases.</strong> The end objective was to have an Amazon EC2 instance with specific files and folders. Amazon S3 is a storage solution from AWS, and hence I stored the files and folders there. As part of provisioning the Amazon EC2 instance, my approach was to download the files and folders from Amazon S3 using the AWS CLI. Provisioning an Amazon EC2 is done using the user data script, so I required that. Also, I needed AWS CLI installed on the Amazon EC2 instance. Moreover, the Amazon EC2 instance also required permissions to access the Amazon S3 bucket. Putting all these together, the sequence of steps were as follows:</span></span></span>

<strong><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Step 1: Provision an Amazon S3 bucket and store files and folders required by the Amazon EC2 instance</span></span></span></strong>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">The Amazon S3 bucket was already created for this specific use case and so I uploaded the files stored in the local repository (<code>files</code> folder).</span></span></span>
<img class="alignnone size-full wp-image-1668" src="https://skundunotes.com/wp-content/uploads/2021/12/59-image-2.png" alt="59-Image-2" width="600" height="322" />
<strong><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Step 2: Provision an Amazon EC2 instance and have a user data script ready</span></span></span></strong>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">When taking this approach, there are multiple factors to consider  <strong>-should the script be run multiple times or only once?</strong> What is the sequence of steps to be executed via user data? What is the size of the user data script? I covered them separately  -<span style="text-decoration: underline"><a href="https://skundunotes.com/2021/11/07/working-with-aws-ec2-user-data-and-terraform/" target="_blank" rel="noopener">Working with Amazon EC2 user data and Terraform.</a></span></span></span></span>

<strong><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Step 3: Attach an IAM role to the Amazon EC2 instance</span></span></span></strong>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">The Amazon EC2 instance required a set of permissions to communicate with the Amazon S3 bucket. I described that in detail at -<span style="text-decoration: underline"><a href="https://skundunotes.com/2021/11/16/attach-iam-role-to-aws-ec2-instance-using-terraform/" target="_blank" rel="noopener">Attach IAM role to Amazon EC2 instance using Terraform.</a></span></span></span></span>

<strong><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Step 4: Install AWS CLI on the Amazon EC2</span></span></span></strong>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I could achieve this objective in two ways if the underlying instance were running Windows. Install the AWS.Tools module for PowerShell or install the AWS CLI. I have two separate notes on them that you may find useful. <span style="text-decoration: underline"><a href="https://skundunotes.com/2021/11/19/install-aws-tools-module-for-powershell-on-aws-ec2-using-user-data-and-terraform/" target="_blank" rel="noopener">Install AWS.Tools module.</a></span> OR <span style="text-decoration: underline"><a href="https://skundunotes.com/2021/12/07/install-aws-cli-on-a-windows-ec2-instance-using-terraform-and-user-data/" target="_blank" rel="noopener">Install AWS CLI.</a></span></span></span></span>

<strong><span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Step 5: Call the S3-CopyObject AWS command</span></span></span></strong>
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">This is the final step, and I completed that via the command shown in the image below in the user data script.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I have a working copy of the Terraform code in my repository at  <span style="text-decoration: underline"><a href="https://github.com/kunduso/ec2-userdata-terraform/tree/add-s3-access" target="_blank" rel="noopener">-add-s3-access</a></span></span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Another critical aspect of working with a user data script is to <strong>provide clear logging</strong>. That comes in handy when dealing with error conditions when building the logic. Also, identify where the user data script (PowerShell) and the logging information are stored. I made these considerations and covered them in the code version stored in the <a href="https://github.com/kunduso/ec2-userdata-terraform/tree/add-s3-access" target="_blank" rel="noopener"><span style="text-decoration: underline">GitHub repository.</span></a> I have an image of the log file of the user data execution below.</span></span></span>
<img class="alignnone size-full wp-image-1669" src="https://skundunotes.com/wp-content/uploads/2021/12/59-image-3.png" alt="59-Image-3" width="744" height="665" />
<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">Comparing the user data script and the log file allows you to understand the logic and process flow. After a few minutes of the <code>terraform apply</code> command, I logged into the Amazon EC2 instance and verified that the two files from the S3 bucket were available in the Amazon EC2 instance.</span></span></span>

<span style="font-size: 18px"><span style="font-family: calibri"><span style="color: #000000">I hope this note was useful. Let me know if you have any questions or suggestions.</span></span></span>
